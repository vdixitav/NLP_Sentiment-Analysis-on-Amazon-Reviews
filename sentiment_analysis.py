# -*- coding: utf-8 -*-
"""Sentiment_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Zq8cspccu3IV_je_AJ5xs7TGpXKqMQQ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.stem.porter import PorterStemmer
nltk.download('stopwords')
from nltk.corpus import stopwords
STOPWORDS=set(stopwords.words('english'))

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from wordcloud import WordCloud
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
import pickle
import re



"""EDA"""

data=pd.read_csv('/content/amazon_alexa.tsv',delimiter='\t',quoting=3) # Changed delimiter to \t

data.shape

data.head()

data.columns.values

data.isnull().sum()

data[data['verified_reviews'].isna()==True]

data.dropna(inplace=True)

data.isnull().sum()

data.shape

data['length']=data['verified_reviews'].apply(len)

data.head()

data.dtypes

data['rating'].value_counts()

data['rating'].value_counts().plot.bar(color='red')
plt.title('rating dustibution count')
plt.xlabel('rating')
plt.ylabel('count')
plt.show()

data['feedback'].value_counts()

data[data['feedback']==0].iloc[1]['verified_reviews']

data['feedback'].value_counts().plot.bar(color='blue')
plt.title(' feedback dustibution count')
plt.xlabel('feedback')
plt.ylabel('count')
plt.show()

data['feedback'].value_counts()

data[data['feedback']==1]['rating'].value_counts()

data['variation'].value_counts()

data.groupby('variation')['rating'].mean()

data['length'].describe()

sns.histplot(data['length'],color= 'blue').set(title='Distribution of lenght of review')

sns.histplot(data['length'],color= 'blue',kde=True).set(title='Distribution of lenght of review')

sns.histplot(data[data['feedback']==0]['length'],color='red').set(title='Distribution of lenght of review if feedback=0')

cv=CountVectorizer(stop_words='english')
words=cv.fit_transform(data.verified_reviews)

revirews=' '.join([review for review in data['verified_reviews']])

wc=WordCloud(background_color='white',max_words=50)

plt.figure(figsize=(10,10))
plt.imshow(wc.generate(revirews))
plt.title('Wordsloud for all reviews', fontsize=10)
plt.axis('off')
plt.show()

neg_reviews=' '.join([review for review in data[data['feedback']==0]['verified_reviews']])
neg_reviews=neg_reviews.lower().split()

pos_reviews=' '.join([review for review in data[data['feedback']==1]['verified_reviews']])
pos_reviews=pos_reviews.lower().split()


# finding words from review which are present in the that feedback category only
unique_negative =[x for x in neg_reviews if x not in pos_reviews]
unique_negative=' '.join(unique_negative)
unique_positive =[x for x in pos_reviews if x not in neg_reviews]
unique_positive=' '.join(unique_positive)

wc=WordCloud(background_color='white',max_words=50)

plt.figure(figsize=(10,10))
plt.imshow(wc.generate(unique_negative))
plt.title('Wordsloud for unique negative reviews', fontsize=10)
plt.axis('off')
plt.show()

wc=WordCloud(background_color='white',max_words=50)

plt.figure(figsize=(10,10))
plt.imshow(wc.generate(unique_positive))
plt.title('Wordsloud for unique positive reviews', fontsize=10)
plt.axis('off')
plt.show()



"""### Preprocessing and modeling"""

corpus = []
stemmer = PorterStemmer()

for i in range(data.shape[0]):
    try:
        review = data['verified_reviews'][i]
    except KeyError:
        continue  # Skip if the index doesn't exist

    if pd.isna(review):
        continue  # Skip if the review is missing or NaN

    review = re.sub('[^a-zA-Z]', ' ', review)
    review = review.lower()
    review = review.split()
    review = [stemmer.stem(word) for word in review if word not in STOPWORDS]
    review = ' '.join(review)

    corpus.append(review)

cv=CountVectorizer(max_features=2500)
X=cv.fit_transform(corpus).toarray()
y=data['feedback'].values

import os
import pickle

# Create directory if it doesn't exist
os.makedirs('Models', exist_ok=True)

# Save the pickle file
with open('Models/countVectoriser.pkl', 'wb') as f:
    pickle.dump(cv, f)

pickle.dump(cv,open('Models/countVectoriser.pkl','wb'))

# checking x and y shape

print(X.shape)
print(y.shape)

y = y[:len(X)]  # Adjust y to match X

X = X[:len(y)]  # Adjust X to match y

import pandas as pd

# Convert X and y to DataFrame and Series, respectively
X_df = pd.DataFrame(X)
y_series = pd.Series(y)

# Concatenate and drop NaN values
combined = pd.concat([X_df, y_series], axis=1).dropna()

# Separate X and y after dropping NaN rows
X_clean = combined.iloc[:, :-1]  # All columns except the last one
y_clean = combined.iloc[:, -1]   # Last column as y

print(X_clean.shape, y_clean.shape)

# Print shapes to verify consistency
print(f"X_clean shape: {X_clean.shape}")
print(f"y_clean shape: {y_clean.shape}")

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=15)

print(f"X_train:{X_train.shape}")
print(f"X_test:{X_test.shape}")
print(f"y_train:{y_train.shape}")
print(f"y_test:{y_test.shape}")

print(f"X_train mx value : {X_train.max()}")
print(f"X_test mx value : {X_test.max()}")

scaler=MinMaxScaler()

x_train_scl=scaler.fit_transform(X_train)
x_test_scl=scaler.transform(X_test)

# solving scaler model

pickle.dump(scaler,open('Models/scaler.pkl','wb'))



"""Random forst classifier"""

# fitting scaled x_train and y_train on random forest calssifier

model_rf=RandomForestClassifier()
model_rf.fit(x_train_scl,y_train)

# accuracy scaled x_train and y_train on random forst

print(f"train accuracy : {model_rf.score(x_train_scl,y_train)}")
print(f"test accuracy : {model_rf.score(x_test_scl,y_test)}")

# predicting on the test set

y_preds=model_rf.predict(x_test_scl)

# confusion matrixc

cm=confusion_matrix(y_test,y_preds)

# confision matrcx display


cm_display=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model_rf.classes_)
cm_display.plot()
plt.show()

"""###KFOLD CROSS VALIDATION"""

accuracies=cross_val_score(estimator=model_rf,X=x_train_scl,y=y_train,cv=10)

print("Accuracy :",accuracies)
print("Mean Accuracy :",accuracies.mean())
print("Standard Deviation :",accuracies.std())

# applying gridsearchcv to get optimal parameter on random forest

params={
    'bootstrap':[True],
    'max_depth':[80,100],
    'min_samples_split':[8,12],
    'n_estimators':[100,300]

}

cv_object=StratifiedKFold(n_splits=2)
grid_search=GridSearchCV(estimator=model_rf,param_grid=params,cv=cv_object,verbose=0,return_train_score=True)
grid_search.fit(x_train_scl,y_train.ravel())

# getting best parameters from grid search cv

print("Best parameter combination : {}".format(grid_search.best_params_))

print("cross validtaion mean accuracy on train set: {}".format(grid_search.cv_results_['mean_train_score'].mean()*100))
print("cross validtaion mean accuracy on test set: {}".format(grid_search.cv_results_['mean_test_score'].mean()*100))
print("Accuracy score for the test set :",accuracy_score(y_test,y_preds))